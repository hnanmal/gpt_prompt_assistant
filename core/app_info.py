# 📁 core/app_info.py

APP_NAME = "GPT Prompt Assistant"
VERSION = "1.0.1"
AUTHOR = "Done by Dumb"
COPYRIGHT = f"© 2025 {AUTHOR}. All rights reserved."

ABOUT_TEXT = f"""{APP_NAME}

개발자: {AUTHOR}
버전: {VERSION}

이 프로그램은 Ollama 모델을 활용한 GPT 기반 프롬프트 분석 도구입니다.

다양한 폴더와 파일로 이루어진 개발 프로젝트를 진행할 때, GPT에게 질문을 하면

    - 기존 작성 파일 및 함수 망각 후 유사 기능의 새로운 파일 및 함수 제안,
    - 과거 GPT 스스로 생성한 코딩의 체계에 반하는 억지 코드 생성,
    - 개발 초기부터 쌓아온 프로그램 아키텍처를 무시하고 새로운 아키텍처 가정 후 파일 및 함수 제안

상기의 문제점이 자주 발생합니다.

따라서 프로젝트의 폴더구성 체계와,
내가 질문한 내용과 관련이 있는 파일의 목록을 함께 프롬프트로 제시해주는 프로그램을 만들었습니다.

GPT에게 질문하기 위한 프롬프트를 보강하기 위해 웹에서 다른 창을 띄워 GPT를 쓰는 것도 가능하지만
굉장히 번거롭고 프로젝트의 구성을 내가 텍스트로 직접 서술해 줘야 하며
GPT 창을 혼동하여 대화방목적과 다른 질문을 실수로 해서
오히려 프로젝트 개발이 더 혼란해지는 경우를 많이 경험하여 만든 프로그램입니다.

---

📌 **중요 안내: Ollama 설치 필요**

이 프로그램은 로컬에서 실행되는 [Ollama](https://ollama.com/) 를 기반으로 작동합니다.  
설치되어 있지 않은 경우, Ollama 공식 웹사이트에서 설치하신 후 프로그램을 사용해 주세요.

- 설치 URL: https://ollama.com/
- 설치 후 `ollama` 명령어가 터미널에서 실행되어야 정상 작동합니다.
- 지원 모델 예: `mistral`, `phi3:mini`, `llama3` 등


※ Ollama 모델은 기본적으로 C드라이브에 설치됩니다. 
C드라이브 용량이 부족하다면 설치 폴더 내의 ollama_move_to_d.bat를 실행해서
모델의 설치 경로를 D드라이브로 옮기십시오.
---

🪪 **License: MIT**

MIT License에 따라 배포되며, 다음 권한이 포함됩니다:

- 사용, 복사, 수정, 병합, 게시, 배포, 서브라이선스, 판매 가능
- 단, 저작권 고지 및 라이선스 고지를 모든 복제물 또는 중요한 부분에 명시해야 합니다.
- 본 소프트웨어는 "있는 그대로" 제공되며, 사용에 따른 어떠한 보증도 하지 않습니다.

{COPYRIGHT}
"""
